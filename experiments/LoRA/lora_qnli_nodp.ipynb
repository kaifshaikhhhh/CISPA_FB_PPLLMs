{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 09:07:39.681869: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-15 09:07:39.853100: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-15 09:07:39.858097: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/opt/software/Java/1.8.0_152/lib:/opt/software/Python/3.6.4-foss-2018a/lib:/opt/software/libffi/3.2.1-GCCcore-6.4.0/lib64:/opt/software/libffi/3.2.1-GCCcore-6.4.0/lib:/opt/software/GMP/6.1.2-GCCcore-6.4.0/lib:/opt/software/SQLite/3.21.0-GCCcore-6.4.0/lib:/opt/software/Tcl/8.6.8-GCCcore-6.4.0/lib:/opt/software/libreadline/7.0-GCCcore-6.4.0/lib:/opt/software/ncurses/6.0-GCCcore-6.4.0/lib:/opt/software/Boost/1.67.0-foss-2018a/lib:/opt/software/zlib/1.2.11-GCCcore-6.4.0/lib:/opt/software/bzip2/1.0.6-GCCcore-6.4.0/lib:/opt/software/ScaLAPACK/2.0.2-gompi-2018a-OpenBLAS-0.2.20/lib:/opt/software/FFTW/3.3.7-gompi-2018a/lib:/opt/software/OpenBLAS/0.2.20-GCC-6.4.0-2.28/lib:/opt/software/imkl/2018.1.163-gompi-2018a/mkl/lib/intel64:/opt/software/imkl/2018.1.163-gompi-2018a/lib/intel64:/opt/software/tbb/2018_U3-GCCcore-6.4.0/build/linux_intel64_gcc_cc6.4.0_libc2.17_kernel3.10.0_release:/opt/software/OpenMPI/2.1.2-GCC-6.4.0-2.28/lib:/opt/software/hwloc/1.11.8-GCCcore-6.4.0/lib:/opt/software/numactl/2.0.11-GCCcore-6.4.0/lib:/opt/software/binutils/2.28-GCCcore-6.4.0/lib:/opt/software/GCCcore/6.4.0/lib/gcc/x86_64-pc-linux-gnu/6.4.0:/opt/software/GCCcore/6.4.0/lib64:/opt/software/GCCcore/6.4.0/lib:/usr/local/cuda-11.2/lib64\n",
      "2023-11-15 09:07:39.858116: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-15 09:07:40.675438: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/opt/software/Java/1.8.0_152/lib:/opt/software/Python/3.6.4-foss-2018a/lib:/opt/software/libffi/3.2.1-GCCcore-6.4.0/lib64:/opt/software/libffi/3.2.1-GCCcore-6.4.0/lib:/opt/software/GMP/6.1.2-GCCcore-6.4.0/lib:/opt/software/SQLite/3.21.0-GCCcore-6.4.0/lib:/opt/software/Tcl/8.6.8-GCCcore-6.4.0/lib:/opt/software/libreadline/7.0-GCCcore-6.4.0/lib:/opt/software/ncurses/6.0-GCCcore-6.4.0/lib:/opt/software/Boost/1.67.0-foss-2018a/lib:/opt/software/zlib/1.2.11-GCCcore-6.4.0/lib:/opt/software/bzip2/1.0.6-GCCcore-6.4.0/lib:/opt/software/ScaLAPACK/2.0.2-gompi-2018a-OpenBLAS-0.2.20/lib:/opt/software/FFTW/3.3.7-gompi-2018a/lib:/opt/software/OpenBLAS/0.2.20-GCC-6.4.0-2.28/lib:/opt/software/imkl/2018.1.163-gompi-2018a/mkl/lib/intel64:/opt/software/imkl/2018.1.163-gompi-2018a/lib/intel64:/opt/software/tbb/2018_U3-GCCcore-6.4.0/build/linux_intel64_gcc_cc6.4.0_libc2.17_kernel3.10.0_release:/opt/software/OpenMPI/2.1.2-GCC-6.4.0-2.28/lib:/opt/software/hwloc/1.11.8-GCCcore-6.4.0/lib:/opt/software/numactl/2.0.11-GCCcore-6.4.0/lib:/opt/software/binutils/2.28-GCCcore-6.4.0/lib:/opt/software/GCCcore/6.4.0/lib/gcc/x86_64-pc-linux-gnu/6.4.0:/opt/software/GCCcore/6.4.0/lib64:/opt/software/GCCcore/6.4.0/lib:/usr/local/cuda-11.2/lib64\n",
      "2023-11-15 09:07:40.676066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/opt/software/Java/1.8.0_152/lib:/opt/software/Python/3.6.4-foss-2018a/lib:/opt/software/libffi/3.2.1-GCCcore-6.4.0/lib64:/opt/software/libffi/3.2.1-GCCcore-6.4.0/lib:/opt/software/GMP/6.1.2-GCCcore-6.4.0/lib:/opt/software/SQLite/3.21.0-GCCcore-6.4.0/lib:/opt/software/Tcl/8.6.8-GCCcore-6.4.0/lib:/opt/software/libreadline/7.0-GCCcore-6.4.0/lib:/opt/software/ncurses/6.0-GCCcore-6.4.0/lib:/opt/software/Boost/1.67.0-foss-2018a/lib:/opt/software/zlib/1.2.11-GCCcore-6.4.0/lib:/opt/software/bzip2/1.0.6-GCCcore-6.4.0/lib:/opt/software/ScaLAPACK/2.0.2-gompi-2018a-OpenBLAS-0.2.20/lib:/opt/software/FFTW/3.3.7-gompi-2018a/lib:/opt/software/OpenBLAS/0.2.20-GCC-6.4.0-2.28/lib:/opt/software/imkl/2018.1.163-gompi-2018a/mkl/lib/intel64:/opt/software/imkl/2018.1.163-gompi-2018a/lib/intel64:/opt/software/tbb/2018_U3-GCCcore-6.4.0/build/linux_intel64_gcc_cc6.4.0_libc2.17_kernel3.10.0_release:/opt/software/OpenMPI/2.1.2-GCC-6.4.0-2.28/lib:/opt/software/hwloc/1.11.8-GCCcore-6.4.0/lib:/opt/software/numactl/2.0.11-GCCcore-6.4.0/lib:/opt/software/binutils/2.28-GCCcore-6.4.0/lib:/opt/software/GCCcore/6.4.0/lib/gcc/x86_64-pc-linux-gnu/6.4.0:/opt/software/GCCcore/6.4.0/lib64:/opt/software/GCCcore/6.4.0/lib:/usr/local/cuda-11.2/lib64\n",
      "2023-11-15 09:07:40.676079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "import opacus\n",
    "from opacus.validators import ModuleValidator\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"prajjwal1/bert-tiny\"\n",
    "EPOCHS = 6\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "dataset = load_dataset(\"glue\", \"qnli\")\n",
    "num_labels = dataset[\"train\"].features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2b758bfa9e4c80838e88907bc5df6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/104743 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fd8984fc93480b8f23344a3d86a97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829f7bfa15c24bf8ad8b17b1388724a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda example: tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"sentence\"],\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    ),\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(['idx'])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'sentence', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 104743\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'sentence', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5463\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'sentence', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5463\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_dataset[\"train\"], shuffle=False, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(tokenized_dataset[\"validation\"], shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = np.inf\n",
    "DELTA = 1\n",
    "MAX_GRAD_NORM = 0.5\n",
    "MAX_PHYSICAL_BATCH_SIZE = int(BATCH_SIZE/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertForSequenceClassification(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 128)\n",
       "          (token_type_embeddings): Embedding(2, 128)\n",
       "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-1): 2 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=128, out_features=128, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(\n",
       "                    in_features=128, out_features=128, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=128, out_features=128, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=128, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=128, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.num_labels = num_labels\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS, \n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules = ['query', 'key', 'value'],\n",
    ")\n",
    "\n",
    "if peft_config is not None:\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.register_full_backward_hook(True)\n",
    "\n",
    "device = torch.device(\"cuda:3\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "errors = ModuleValidator.validate(model, strict=False)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(params=model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "\n",
    "model, optimizer, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    target_epsilon=EPSILON,\n",
    "    target_delta=DELTA,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    "    batch_first=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Sigma = 10.000 | C = 0.5 | Initial DP (ε, δ) = (0, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Sigma = {optimizer.noise_multiplier:.3f} | C = {optimizer.max_grad_norm} | Initial DP (ε, δ) = ({privacy_engine.get_epsilon(DELTA)}, {DELTA})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 12546 || All Parameters: 4398724 || Trainable Parameters (%): 0.29\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Parameters: {trainable_params} || All Parameters: {all_param} || Trainable Parameters (%): {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    epsilon = []\n",
    "\n",
    "    with BatchMemoryManager(\n",
    "        data_loader=train_dataloader, \n",
    "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE,\n",
    "        optimizer=optimizer,\n",
    "        ) as memory_safe_data_loader:\n",
    "\n",
    "        for i, batch in tqdm(enumerate(memory_safe_data_loader), total=len(memory_safe_data_loader), desc=f\"Training Epoch: {epoch}\"):\n",
    "            \n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = criterion(outputs.logits, batch[\"labels\"])\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if i % 8000 == 0:\n",
    "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "\n",
    "                print(f\"Training Epoch: {epoch} | Loss: {np.mean(losses):.6f} | ε = {epsilon:.2f}\")                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dataloader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Test\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = criterion(outputs.logits, batch[\"labels\"])\n",
    "\n",
    "            preds = outputs.logits.argmax(dim=-1)\n",
    "            acc = accuracy_score(preds.cpu().numpy(), batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            accuracies.append(acc.item())\n",
    "\n",
    "    acc = np.mean(accuracies)\n",
    "    loss = np.mean(losses)\n",
    "\n",
    "    print(\n",
    "        f\"Test set: Loss: {loss:.4f}, Accuracy: {acc*100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fb7434d1de49ea8a198b0bfb51e818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 6 Epochs:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d642481e20843cda5fdc084b3856975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 1:   0%|          | 0/1636 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 1 | Loss: 0.727757 | ε = 0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc7bec8a123458bac02aeba03b6f48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 2:   0%|          | 0/1636 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 2 | Loss: 0.689211 | ε = -3.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af666dab5ba48e684591f230187e399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 3:   0%|          | 0/1636 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 3 | Loss: 0.746207 | ε = -3.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6a3613859f46ccb1c014f0c8728bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 4:   0%|          | 0/1636 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 | Loss: 0.768811 | ε = -3.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355a484541254f778de14799170a0725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 5:   0%|          | 0/1636 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 5 | Loss: 0.803027 | ε = -3.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9172e486f7f34087be8ad8f32b39db15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 6:   0%|          | 0/1636 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 6 | Loss: 1.084349 | ε = -3.35\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(EPOCHS), desc=f'Training {EPOCHS} Epochs'):\n",
    "    train(model, train_dataloader, optimizer, epoch + 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DP Guarantee (ε, δ)-DP = (-3.35, 1)\n"
     ]
    }
   ],
   "source": [
    "final_epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "print(f\"Final DP Guarantee (ε, δ)-DP = ({final_epsilon:.2f}, {DELTA})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdb850dc3d441b2a15ab6e08090525b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Loss: 1.0330, Accuracy: 59.07%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0329760096289895, 0.5906927573145245)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
