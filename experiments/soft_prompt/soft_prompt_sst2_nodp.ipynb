{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "from peft import PromptEncoderConfig, TaskType, get_peft_model\n",
    "\n",
    "import opacus\n",
    "from opacus.validators import ModuleValidator\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, DataCollatorWithPadding\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"prajjwal1/bert-tiny\"\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 32\n",
    "LR = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('glue', 'sst2')\n",
    "num_labels = dataset[\"train\"].features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_side = \"right\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    outputs = tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"idx\", \"sentence\"],\n",
    ")\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], \n",
    "    shuffle=True, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], \n",
    "    batch_size=BATCH_SIZE, \n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = np.inf\n",
    "DELTA = 1\n",
    "MAX_GRAD_NORM = 0\n",
    "MAX_PHYSICAL_BATCH_SIZE = int(BATCH_SIZE/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-1): 2 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): ModulesToSaveWrapper(\n",
       "      (original_module): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (modules_to_save): ModuleDict(\n",
       "        (default): Linear(in_features=128, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): PromptEncoder(\n",
       "      (embedding): Embedding(18, 128)\n",
       "      (mlp_head): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.num_labels = num_labels\n",
    "\n",
    "peft_config = PromptEncoderConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    num_virtual_tokens=18,\n",
    "    encoder_hidden_size=128\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "errors = ModuleValidator.validate(model, strict=False)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(params=model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "\n",
    "model, optimizer, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    target_epsilon=EPSILON,\n",
    "    target_delta=DELTA,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    "    batch_first=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Sigma = 10.000 | C = 0 | Initial DP (ε, δ) = (0, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Sigma = {optimizer.noise_multiplier:.3f} | C = {optimizer.max_grad_norm} | Initial DP (ε, δ) = ({privacy_engine.get_epsilon(DELTA)}, {DELTA})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 52098 || All Parameters: 4438276 || Trainable Parameters (%): 1.17\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Parameters: {trainable_params} || All Parameters: {all_param} || Trainable Parameters (%): {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    epsilon = []\n",
    "\n",
    "    for i, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Training Epoch: {epoch}\"):\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = criterion(outputs.logits, batch[\"labels\"])\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if i % 64000 == 0:\n",
    "            epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "\n",
    "            print(f\"Training Epoch: {epoch} | Loss: {np.mean(losses):.6f} | ε = {epsilon:.2f}\")\n",
    "\n",
    "    return losses, epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dataloader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Test\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        eval_loss += loss.detach().float()\n",
    "        preds = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "        acc = accuracy_score(preds.cpu().numpy(), batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "    print(\n",
    "        f\"Test set: Loss: {eval_loss:.4f}, Accuracy: {acc*100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    return eval_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d7dd7278564f50927128ee238f34e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 4 Epochs:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c9e88505ab4f828cb976a0f21ae1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 1:   0%|          | 0/2105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 1 | Loss: 0.702038 | ε = -3.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9978537e4120442388f3996154468f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 2:   0%|          | 0/2105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 2 | Loss: 0.704225 | ε = -3.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0771bcb562d448e930edc71046f4c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 3:   0%|          | 0/2105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 3 | Loss: 0.695432 | ε = -3.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2107a7fef0844829de6798ee911e42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 4:   0%|          | 0/2105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 | Loss: 0.682204 | ε = -3.35\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(EPOCHS), desc=f'Training {EPOCHS} Epochs'):\n",
    "    train(model, train_dataloader, optimizer, epoch + 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DP Guarantee (ε, δ)-DP = (-3.35, 1)\n"
     ]
    }
   ],
   "source": [
    "final_epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "print(f\"Final DP Guarantee (ε, δ)-DP = ({final_epsilon:.2f}, {DELTA})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6515d1877ff444879f5ca8359fda9940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Loss: 0.7221, Accuracy: 50.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.7221, device='cuda:0'), 0.5)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
